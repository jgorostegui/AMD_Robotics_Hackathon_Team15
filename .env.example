# HuggingFace Authentication
HF_TOKEN=your_huggingface_token_here
HF_USER=your_huggingface_username

# Robot Hardware Ports
LEADER_PORT=/dev/ttyACM0
FOLLOWER_PORT=/dev/ttyACM1
LEADER_ID=leader_arm
FOLLOWER_ID=follower_arm

# Camera Configuration (3 cameras)
TOP_CAMERA=/dev/video4          # Logitech overhead camera
SIDE_CAMERA=/dev/video2         # Side view camera
GRIPPER_CAMERA=/dev/video6      # Gripper-mounted camera
CAMERA_WIDTH=640
CAMERA_HEIGHT=480
CAMERA_FPS=30

# Dataset Settings
DATASET_NAME=mission2_smolvla_multitask
DATASET_TASK="Pick object and place in target location"
DATASET_NUM_EPISODES=50
DATASET_EPISODE_TIME=30
DATASET_RESET_TIME=10
DATASET_ROOT=${HOME}/so101_datasets

# VLA / SmolVLA multi-task prompts
TASKS_JSON=mission2/tasks_smolvla.json

# Weights & Biases
WANDB_PROJECT=amd-hackathon-2025
WANDB_ENTITY=your_wandb_team

# Mission 2 (Connect4) calibration
MISSION2_CALIBRATION_PATH=mission2/vision/calibration.json
MISSION2_CORNER_MODE=fixed  # auto|fixed
MISSION2_SIDEBAR_WIDTH_PX=520
# Grid inference method for warped top-down view: sample_hsv|hough|robust
MISSION2_GRID_METHOD=sample_hsv
